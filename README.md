# Machine-Learning-final

Tο train_hh_gt.csv και το train_hh_features.csv περιέχουν και τα δύο πληροφορίες που θα χρειαστούν στο training dataset, οπότε γίνεται στην ένωσή τους βάση το household ID που έχουν και το survey ID στο οποίο ανήκουν.  
Εφαρμόζεται συμπλήρωης των κενών τιμών, scaling και one-hot encoding.


Για όλα τα μοντέλα εφαρμόστηκε η ίδια διαδικασία αξιολόγησης. Χρησιμοποιήθηκε GroupKFold με ομαδοποίηση βάσει του survey_id, έτσι ώστε κάθε survey να εμφανίζεται αποκλειστικά είτε στο σύνολο εκπαίδευσης είτε στο σύνολο επικύρωσης. Με τον τρόπο αυτό προσομοιώνεται η γενίκευση του μοντέλου σε δεδομένα διαφορετικών ετών συλλογής.

Σε κάθε fold το μοντέλο εκπαιδεύεται στο training set και προβλέπει την ημερήσια κατά κεφαλήν κατανάλωση των νοικοκυριών στο validation set. Από τις προβλέψεις αυτές υπολογίζονται δύο κατηγορίες σφαλμάτων:  
(α) σφάλματα σε επίπεδο νοικοκυριού, με χρήση των μετρικών MAE, και στη συνέχεια  
(β) σφάλματα στους poverty rates.

Τα poverty rates προκύπτουν συγκρίνοντας την προβλεπόμενη κατανάλωση κάθε νοικοκυριού με μια σειρά δοσμένων από dataset csv κατωφλίων κατανάλωσης και εφαρμόζοντας τα αντίστοιχα βάρη των νοικοκυριών. Τα προβλεπόμενα poverty rates συγκρίνονται με τα πραγματικα και υπολογίζεται το Mean Absolute Error.

Η διαδικασία επαναλαμβάνεται για όλα τα folds και στο τέλος υπολογίζεται ο μέσος όρος των μετρικών. Για τα μοντέλα που διαθέτουν υπερπαραμέτρους (Random Forest, XGBoost και MLP), δοκιμάστηκαν διαφορετικές ρυθμίσεις και επιλέχθηκε εκείνη που ελαχιστοποιεί το σφάλμα στους poverty rates.

( Σχόλια και σύντομη επεξήγση για βήματα/ροή υπάρχουν και στον κώδικα.)

---

## Επιλογή και σύγκριση αλγορίθμων

Οι αλγόριθμοι που επιλέχθηκαν είναι οι Linear Regression, Random Forest, XGBoost.  
Ο λόγος για τον οποίο χρησιμοποιηθηκε η γραμμική παλινδρόμηση είναι γιατι εξετλαζει γραμμικόττα σχεσεων και είναι βασικός αλγόριθμς οπότε χρειαζόταν να εξεταστεί στην περίπτωση που θα μπορούς ένα λύσει το πρόβλημα (αν και σε τόσο ποερίπλοκα προβλήματα αναμ’ενεται να μην πάει καλά). Τα Random Forest, XGBoost και MLP επιλέχθηκαν γιατί μπορούν να αναπαραστήσουν μη γραμμικές σχέσεις.

Τα αποτελέσματα δείχνουν καλύτερη απόδοσης όσο αυξάνεται η πολυπλοκότητα του μοντέλου.

---

## Περιορισμοί των μοντέλων

Όπως αναφέρθηκε και όπως φαίνεται η γραμμική παλινδρόμηση δεν καταφερνει να ανταπεξέλθει στις περίπλοκες σχεσεις των δεδομένων χρησιμοποιώντας γραμμικές σχέσεις. Από την άλλη, τα Random Forest, XGBoost (trees) και το MLP είναι πιο ευέλικτα, αλλά απαιτούν περισσότερo χρόνο εκπαίδεσης.

- Linear Regression: δεν συλλαμβάνει μη γραμμικές σχέσεις.  
- Random Forest: μπορεί να υπερπροσαρμοστεί και δεν αποδίδει πάντα καλά σε πολύ υψηλές διαστάσεις.  
- XGBoost: απαιτεί περισσότερο χ΄ρονο εκπαίδευσης και από τα 4.  
- MLP: χρειάζεται πολλά δεδομένα και σωστή κανονικοποίηση.


Τα μοντέλα αποδίδουν καλύτερα όταν υπάρχουν σαφή μοτίβα μεταξύ χαρακτηριστικών και αρκετά δεδομένα, ενώ επηρρεάζοται από ακραίες τιμές, ιδιαίτερα για τα πιο σύνθετα μοντέλα.

---

## Σημαντικότητα χαρακτηριστικών

Τα μοντέλα δίνουν μεγαλύτερη έμφαση σε χαρακτηριστικά που σχετίζονται άμεσα με το εισόδημα, τη σύνθεση του νοικοκυριού και τις βασικές συνθήκες διαβίωσης καθώς αυτά είναι πιο χρήσιμα για την ποιότητα των προβλέψεων και άρα θα επηρεάζουν την κατανάλωση και, κατ’ επέκταση, τα poverty rates.

### Θα βοηθούσε πιθανώς

- Προσθήκη περισσότερων ποιοτικών χαρακτηριστικών (π.χ. δημογραφικά, οικονομικοί δείκτες).  
- καθαρισμός και μείωση θορύβου (να μην εχει ελλιπείς τιμές).  
- Περισσότερα δείγματα για καλύτερη εκπαίδευση των μοντέλων.  
- Πιθανως αν ειχε και δεδομένα ανά survey σαν επιπλέον πληροφορία


---
Σε όλες τις προσπάθειες submit έβγαζε σφάλμα, οπότε σαν ένδειξη ότι έγνε προσπάθεια υποβολής δίνεται η παρακλατω εικόνα:
<img width="857" height="710" alt="Στιγμιότυπο οθόνης (1074)" src="https://github.com/user-attachments/assets/b6559098-35f8-4901-b907-d5c3ae9d15ff" />
